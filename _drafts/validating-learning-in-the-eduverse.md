---
layout: post
title: Validating Self Learning From The Eduverse
---

{{ page.title }}
================

Lately there have been a lot of new and old entities offering self
directed learning online; from traditional universities like MIT, with
its Open Courseware, to brand new entities like Khan Acadamy, Dabble,
Code Academy and Mentor Mob. As a self tought Software Engineer I
can't help but be extatic that these new ways to learn are popping up
like mushrooms. Learning should be as low cost as practicle and
available to anyone with the drive and guts to teach themselves.

However when I put on my Employer/Interviewer/Project Leader hat I
begin to think that there is a piece missing. That piece is the
validation of the learning that a person has accomplished. Lets
explore an example; lets say that a person has gone through and tought
themselves everything they can about french painters of the
renessance. I (for some reason) am a person looking for people skilled
in identifying paintings by french painters of the renessance. How do
I know that what the learner claims to have learned is something that
they have actually learned? Traditional instutitions attempt to solve
this problem by having a litmus test that results in a degree. The
litmus test varies from university to university and and type of
degree but there is usually some kind of test that claims to **prove**
that the learner has learned what he claims to have
learned. Unfortunately, most universities do a very poor job of this
validation, at least in the field of Computer Science[1].

While traditional institutions of learning try (and usually fail to
succeed) in accomplishing this validation. These new institutions do
not. This is a problem that must be solved before this new learning
can be taken seriously as a valid method to gain knowledge that you
must at some point prove that you have.

Let me make a small aside here, I am a fundamental believer in the
idea that learning is a goal and a pleasure unto itself. If you are
using any method at all to learn simply because you are interested in
a certain topic or simply interested in learning then there and you
never expect to need to prove that you have that knowledge then you
have no need at all to validate your learning. Learn, be happy and
enjoy the journey. I strongly suspect that folks on this path are the
exception rather then the rule.

So how do we prove that we have knowledge. The traditional low
resource (ie inexpensive) methods of validation don't really work
well, multiple choice tests, simple essay questions etc. A good
example of this is certifications in the tech industry. They are
generally so easy to get and such a poor indicator of knowledge that
they have become a *negative* indicator to many inteviewers, my self
included. This is the same problem that traditional institutions
have. They rely so heavily on easily administered tests of this
variety that it reduces the value of the validation they claim to do.

So whats the solution? Its fortunate for us the that companies have
worked out something that attempts to solve this problem in the same
way that higher level degrees have. That is the interview process as
practiced at companies like Amazon and Google[2]. That is an intense
verbal process of question and answer where the interviewer tailors
the questions to the knowledge and skills of the interviews. The
interviewers dig into the knowledge that the interviwees have looking
for where that knowledge as profound and where it is less so. The
purpose of this interview is not to pass or fail the interviewee it is
simply to come up with a rational unbaised assessment of that
interviewees knowledge in the chosen subject area.

There are problems with this approach of course; time-wise its
expensive, skilled interviewers are few and far between, the value of
the validation depends quite a lot on how well you know the
interviewer and how much you trust their judgment. Still its far and
away the only way that has the potential for successfuly validating
knowledge at the moment. That said then how do we mitigate these
problems. How do we create a substrate to evaluate interviewers, to
build trust in a interviewer's validation without having a personal
relationship with that interviewer. If we solve that problem how do we
then take that interviewer's reputation and use that to give
'confidence' to the interviewee he has validated.

Lets take a real world example and try to boil it down to something
that is repeatable and removes the personal relationships that are
involved. Lets say we are trying to validate someone's knowledge in
physics. Lets also say that we set up an interview with him with
Stephan Hawking. Stephan Hawking seems to know his stuff, he generally
has the respect of his peers and he is certainly elegant in talking
about physics to the masses. For the purposes of this excersize lets
say that Stephen Hawking is also a good interviewer (I have no clue
either way about this, hence one of the problems we have to solve). So
if Stephen spent 6 hours with this person that claims to be a
physicist and afterwords said 'This guy is at least as good as me'. We
could probably reliably assume that this guy is a physicist and a
pretty darn good one at that. Now lets say that we wanted a second
opinion. Lets say we wanted a second opinion and we grabbed Kip
Thorne, he interviews our new physicist and also claims 'That guy is
pretty good, probably as good as me'. That second evaluation has not
really made us think that this physicist is any better, but it has
backed up and reinforced our idea that this guy is a pretty good
physicist. If someone else comes along, even another good physicist
and claims 'Hey this guy is not so good' its probably not going to
shake our belief in this person to much. However, if 20 respected
phycists come along and say, 'This guy sucks' it probably will shake
our belief not only in this guy, but in the ability of Thorne and
Hawking to interview, even when it doesnt shake our confidence in them
as phycists themselves.

So this gives us a emperical approach to validation that seems to have
historically worked. We must still remove the need for direct
relationships. In the above example, we have a loose connection to
both Thorne and Hawking through thier public personas. While that is
valiable, we can not have that same knowledge about all the potential
great interviewers out there even if they have the same physics
knowledge as these two luminaries as well as skill as an
interviewer. As with so many things, I think we can reduce this to
simple math with a few leaps to get past the seed problem.







[1] This is not universally true. For example the
[University of Waterloo](http://uwaterloo.ca/) does an excellent job
of both teaching Computer Science and validating that the students
they give degrees too have the knowledge they claim to have. That is
very much not the case with most other schools, in my experiance.

[2] Lots of companies are really horrible at interviewing. Even Amazon
and Google don't get it right all the time. Inteviewing is skill that
is very difficult to develop and it takes skilled inteviewers to
really dig in on and validate knowledge. If you have goon through and
interview process its very highly probable that it was a poor
interview conducted by unskilled interviewers. Dont use that interview
as a measure to judge by. However, if you have goon through and
interview and afterwords felt like every ounce of knowledge and
strength got wrung out of you you may have been interviewed by skilled
interviewers.
